{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorData:\n",
    "    def __init__(self, sensor_name: str, dataframe: pd.DataFrame):\n",
    "        self.sensor_name = sensor_name\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "@dataclass\n",
    "class Machine:\n",
    "    machine_name: str    \n",
    "    labels: pd.DataFrame\n",
    "    sensors: List[SensorData] = field(default_factory=list)\n",
    "    lebels_post_fix: pd.DataFrame = None\n",
    "    sensors_post_fix: List[SensorData] = None\n",
    "\n",
    "    def add_sensor(self, sensor_data: SensorData):\n",
    "        self.sensors.append(sensor_data)\n",
    "\n",
    "        if sensor_data.dataframe.shape[1] != len(self.labels):\n",
    "            raise ValueError(f\"Error adding machine {self.machine_name}, number of labels ({len(self.labels)}) != sensor data columns ({sensor_data.dataframe.shape[1]})\")\n",
    "\n",
    "    def get_sensor_data_by_name(self, sensor_name: str) -> SensorData:\n",
    "        sensor_data = [x for x in self.sensors if x.sensor_name.lower() == sensor_name.lower()]\n",
    "        return sensor_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_file(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a single CSV file into a DataFrame.\"\"\"\n",
    "    return pd.read_csv(filepath, sep=';', index_col='Time [s]')\n",
    "\n",
    "def segment_by_time_range(dataframe: pd.DataFrame, time_range: Tuple[float, float]) -> pd.DataFrame:\n",
    "    \"\"\"Segment the data based on the provided time range.\"\"\"\n",
    "    start_time, end_time = time_range\n",
    "    return dataframe[(dataframe.index >= start_time) & (dataframe.index <= end_time)]\n",
    "\n",
    "def extract_sensor_name(column_name: str) -> str:\n",
    "    \"\"\"Extract sensor name from the column name.\"\"\"\n",
    "    return column_name.split('_')[3]  # Assuming the sensor name is always in the same position\n",
    "\n",
    "def combine_sensor_columns(sensor_columns: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Combine multiple sensor columns into a single dataframe.\"\"\"\n",
    "    return pd.concat(sensor_columns, axis=1)\n",
    "\n",
    "def create_machine_object(machine_file: str, label_file: str, time_range: Tuple[float, float]) -> Machine:\n",
    "    \"\"\"Create a machine object for a specific machine file within a given time range.\"\"\"\n",
    "    machine_name = Path(machine_file).stem\n",
    "\n",
    "    machine_df = load_csv_file(machine_file)\n",
    "    label_df = np.array(pd.read_excel(label_file, header=None))\n",
    "    \n",
    "    # Segment the machine data by the provided time range\n",
    "    segmented_df = segment_by_time_range(machine_df, time_range)\n",
    "\n",
    "    machine_df = segmented_df.dropna(axis=1)\n",
    "    \n",
    "    # Create machine object\n",
    "    machine = Machine(machine_name, label_df)\n",
    "    \n",
    "    # Dictionary to group columns by sensor name\n",
    "    sensor_columns = {}\n",
    "    \n",
    "    # Group columns by sensor name\n",
    "    for column in machine_df.columns:\n",
    "        sensor_name = extract_sensor_name(column)\n",
    "        if sensor_name not in sensor_columns:\n",
    "            sensor_columns[sensor_name] = []\n",
    "        sensor_columns[sensor_name].append(machine_df[[column]])  # Append the dataframe for this column\n",
    "    \n",
    "    # For each sensor, combine the relevant columns and store them as SensorData\n",
    "    for sensor_name, columns in sensor_columns.items():\n",
    "        combined_sensor_df = combine_sensor_columns(columns)\n",
    "        machine.add_sensor(SensorData(sensor_name, combined_sensor_df))\n",
    "    \n",
    "    return machine\n",
    "\n",
    "\n",
    "def calculate_envelope(sensor_df: pd.DataFrame, k: float = 1.0) -> Tuple[pd.Series, pd.Series]:\n",
    "     # Calculate mean and standard deviation along each column (if multiple columns are present)\n",
    "    mean_values = sensor_df.mean(axis=1)\n",
    "    std_values = sensor_df.std(axis=1)\n",
    "    \n",
    "    # Calculate the envelope as mean + k * std\n",
    "    envelope_high = mean_values + k * std_values\n",
    "    envelope_low = mean_values - k * std_values\n",
    "\n",
    "    return envelope_low.squeeze(), envelope_high.squeeze()\n",
    "\n",
    "\n",
    "def plot_sensor_envelope(envelope: tuple, sensor_label_0: pd.DataFrame, sensor_label_1: pd.DataFrame, k, title: str):\n",
    "    \"\"\"\n",
    "    Plot the envelope (mean + k*std) for a given sensor's dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - sensor_df: DataFrame containing sensor data (single sensor with multiple columns)\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    # Plot the original data and the envelope\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot each column in the dataframe\n",
    "    for column in sensor_label_0.columns:\n",
    "        plt.plot(sensor_label_0.index, sensor_label_0[column], label=None, color='green', alpha=0.7)\n",
    "\n",
    "    # Plot each column in the dataframe\n",
    "    for column in sensor_label_1.columns:\n",
    "        plt.plot(sensor_label_1.index, sensor_label_1[column], label=None, color='red', alpha=0.7)\n",
    "    \n",
    "    # Plot the envelope\n",
    "    plt.plot(sensor_label_0.index, envelope[1], label=f'Envelope High (mean + {k}*std)', color='black', linewidth=2)\n",
    "    plt.plot(sensor_label_0.index, envelope[0], label=f'Envelope Low (mean - {k}*std)', color='black', linewidth=2)\n",
    "\n",
    "    # Add titles and labels\n",
    "    plt.title(f'{title} - Sensor Data with Envelope')\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Sensor Value')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_machine_object() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m time_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m17.70\u001b[39m)  \u001b[38;5;66;03m# Example time range from 0 to 120 seconds\u001b[39;00m\n\u001b[0;32m      5\u001b[0m beta_envelope \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 7\u001b[0m machine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_machine_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmachine_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m sensor_sx \u001b[38;5;241m=\u001b[39m machine\u001b[38;5;241m.\u001b[39mget_sensor_data_by_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdataframe\n\u001b[0;32m     11\u001b[0m sensor_sx_data_label_1 \u001b[38;5;241m=\u001b[39m sensor_sx\u001b[38;5;241m.\u001b[39mloc[:, machine\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m]\n",
      "\u001b[1;31mTypeError\u001b[0m: create_machine_object() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "label_file = Path(\"labels\\\\11.xlsx\")\n",
    "machine_file = Path(\"machine_data\\\\11.csv\")\n",
    "time_range = (0, 17.70)  # Example time range from 0 to 120 seconds\n",
    "beta_envelope = 2\n",
    "\n",
    "machine = create_machine_object(machine_file, label_file, time_range)\n",
    "\n",
    "sensor_sx = machine.get_sensor_data_by_name(\"s5\").dataframe\n",
    "\n",
    "sensor_sx_data_label_1 = sensor_sx.loc[:, machine.labels == True]\n",
    "sensor_sx_data_label_0 = sensor_sx.loc[:, machine.labels == False]\n",
    "\n",
    "envelope = calculate_envelope(sensor_sx_data_label_0, beta_envelope)\n",
    "\n",
    "plot_sensor_envelope(envelope, sensor_sx_data_label_0, sensor_sx_data_label_1, beta_envelope, \"Machine 11\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple machines (cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = (0.2, 17.70)  # Example time range from 0 to 120 seconds\n",
    "sensor_name = \"s5\"\n",
    "machine_cnt = 15\n",
    "beta_envelope = 2\n",
    "envelope_min_total_violation = 20 # min data points outside the evelope to be labelled as \"1\"\n",
    "replacement_dates = {} #{\"7\": 109, \"11\": 95, \"12\": 74, \"14\": 52} # maps machine number to first index after replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'machine_cnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m machine_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m skipped_names \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[43mmachine_cnt\u001b[49m):\n\u001b[0;32m      5\u001b[0m     label_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     machine_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmachine_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n",
      "\u001b[1;31mNameError\u001b[0m: name 'machine_cnt' is not defined"
     ]
    }
   ],
   "source": [
    "machine_list = []\n",
    "skipped_names = []\n",
    "\n",
    "for i in range(1, machine_cnt):\n",
    "    label_file = Path(f\"labels\\\\{i}.xlsx\")\n",
    "    machine_file = Path(f\"machine_data\\\\{i}.csv\")    \n",
    "    \n",
    "    try:\n",
    "        machine = create_machine_object(machine_file, label_file, time_range)\n",
    "    except Exception as e:\n",
    "        print(\"skipping \", str(i))\n",
    "        skipped_names.append(str(i))\n",
    "        continue\n",
    "    else:\n",
    "        machine_list.append(machine)\n",
    "\n",
    "print(f\"Skipping machines {skipped_names} (for nan values or missing .csv file)\")\n",
    "\n",
    "tmp = (set(replacement_dates.keys()) - set(skipped_names)) - set([m.machine_name for m in machine_list])\n",
    "assert(len(tmp) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rom sklearn.base import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def classify_using_envelope(test_df: pd.DataFrame, envelope: Tuple[pd.Series, pd.Series], min_total_violation: int = 100):\n",
    "    predictions = []\n",
    "\n",
    "    env_low = envelope[0].squeeze()\n",
    "    env_high = envelope[1].squeeze()\n",
    "\n",
    "    for _, series in test_df.items():\n",
    "        series = series.squeeze()\n",
    "        violations = (series < env_low) | (series > env_high)\n",
    "        predictions.append(violations.sum() > min_total_violation)\n",
    "\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multi_machine_data(training_machines: List[Machine]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Merge sensor data and labels from all training machines\"\"\"\n",
    "\n",
    "    print(f\"Merging training data from {len(training_machines)} machines\")\n",
    "\n",
    "    # merge training labels\n",
    "    training_labels = training_machines[0].labels\n",
    "    for machine in training_machines[1:]:\n",
    "        training_labels = np.concatenate([training_labels, machine.labels], axis=0)\n",
    "\n",
    "    assert(training_labels.shape[1] == 1)\n",
    "\n",
    "    # merge training data series\n",
    "    training_dfs = [x.get_sensor_data_by_name(sensor_name).dataframe for x in training_machines]\n",
    "    training_machines[0].labels\n",
    "    \n",
    "    training_df_combined = training_dfs[0]    \n",
    "    for df in training_dfs[1:]:\n",
    "        training_df_combined = pd.concat([training_df_combined, df], axis=1)\n",
    "        \n",
    "    assert(training_labels.shape[0] == training_df_combined.shape[1])\n",
    "\n",
    "    return (training_df_combined, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_data_by_label(sensor_df: pd.DataFrame, label_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    test_data_1 = sensor_df.loc[:, label_df == True]\n",
    "    test_data_0 = sensor_df.loc[:, label_df == False]\n",
    "\n",
    "    return test_data_0, test_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging training data from 13 machines\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m test_machine: Machine \u001b[38;5;66;03m# test machine (i) against all other machines\u001b[39;00m\n\u001b[0;32m     10\u001b[0m training_machines: List[Machine] \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m j, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(machine_list) \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m i]\n\u001b[1;32m---> 12\u001b[0m training_df_combined, training_labels_combined \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_multi_machine_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_machines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m training_data_0, training_data_1 \u001b[38;5;241m=\u001b[39m split_training_data_by_label(training_df_combined, training_labels_combined)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create envelope from training data with label 0 (no defect)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mcombine_multi_machine_data\u001b[1;34m(training_machines)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m training_dfs[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m     19\u001b[0m     training_df_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([training_df_combined, df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(training_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m training_df_combined\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (training_df_combined, training_labels)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "f1_scores = []\n",
    "false_positive_rate = []\n",
    "\n",
    "# Perform cross validation\n",
    "for _, test_machine in enumerate(machine_list):\n",
    "    test_machine: Machine # test machine (i) against all other machines\n",
    "\n",
    "    training_machines: List[Machine] = [x for j, x in enumerate(machine_list) if j != i]\n",
    "    \n",
    "    training_df_combined, training_labels_combined = combine_multi_machine_data(training_machines)\n",
    "\n",
    "    training_data_0, training_data_1 = split_training_data_by_label(training_df_combined, training_labels_combined)\n",
    "\n",
    "    # Create envelope from training data with label 0 (no defect)\n",
    "    envelope = calculate_envelope(training_data_0, beta_envelope)\n",
    "\n",
    "    test_sensor_df = test_machine.get_sensor_data_by_name(sensor_name).dataframe\n",
    "\n",
    "    test_data_0, test_data_1 = split_training_data_by_label(test_sensor_df, test_machine.labels)\n",
    "\n",
    "    plot_sensor_envelope(envelope, test_data_0, test_data_1, beta_envelope, f\"Machine {test_machine.machine_name} Sensor {sensor_name}\")\n",
    "\n",
    "    predictions = classify_using_envelope(test_sensor_df, envelope, min_total_violation=envelope_min_total_violation)\n",
    "    \n",
    "    false_positives = int(((test_machine.labels == False) & (predictions == True)).sum())\n",
    "    true_negatives = int(((test_machine.labels == False) & (predictions == False)).sum())\n",
    "\n",
    "    false_positive_rate.append((test_machine.machine_name, false_positives / (false_positives + true_negatives)))\n",
    "   \n",
    "    if (test_machine.labels == True).sum() > 0:\n",
    "        f1 = f1_score(test_machine.labels, predictions)\n",
    "        f1_scores.append((test_machine.machine_name, f1))\n",
    "    else:\n",
    "        f1_scores.append((test_machine.machine_name, None))\n",
    "\n",
    "# Data for plotting\n",
    "categories = [f\"Machine {m.machine_name}\" for m in machine_list]\n",
    "data =[[\"FPR\"] + [float(x[1]) if x[1] is not None else None for x in false_positive_rate],\n",
    "       [\"F1\"] + [float(x[1]) if x[1] is not None else None for x in f1_scores]]\n",
    "\n",
    "print(tabulate(data, headers=categories, tablefmt='grid'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
